{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe54199",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace83175",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1cdf68-8b02-44ae-8209-7bf9cf0fef25",
   "metadata": {},
   "source": [
    "# SimCLR\n",
    "W poprzednim zeszycie rozważana była estymacja rozkładu z wykorzystaniem NCE. InfoNCE jest jego rozszerzeniem do problemu wieloklasowego i zostało wykorzystane w licznych metodach kontrastowego uczenia samonadzorowanego. W niniejszym zeszycie skupimy się na metodzie `SimCLR` [(Chen et al., 2020)](https://arxiv.org/abs/2002.05709). **Należy się dokładnie zapoznać z ideą i zasadą działania SimCLR** (wykorzystując materiały z wykładu oraz publikacje, bądź inne materiały dostępne w sieci). \n",
    "\n",
    "\n",
    "W niniejszym zeszycie należy wykonać zadania z zakresu implementacji metody `SimCLR` oraz badania jej hiperparametrów. Model oraz trenowanie zaimplementowano z wykorzystaniem `pytorch_lightning`. Żeby zrozumieć dobrze implementacje, należy zapoznać się z klasą bazową `SSLBase` i ewaluacją na zadaniu docelowym, która została w tej klasie zaimplementowana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0035b4d-d7f1-4a68-b519-cb6415f4c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe4b31-c797-49d6-9932-ff9a06c98b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "from lightning_fabric import seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning import Trainer\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src.data import VisionDatamodule\n",
    "from src.ssl_base import SSLBase\n",
    "from src.networks import SmallConvnet, MLP\n",
    "from src.augmentations import get_default_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d01b43-f28b-4b7b-98aa-898713849009",
   "metadata": {},
   "source": [
    "# Zbiór danych\n",
    "Do uczenia `SimCLR` wykorzystamy wypróbkowany podzbiór zbioru MNIST. Warto zaznaczyć, że jest to wybór podyktowany tylko i wyłącznie ograniczeniami w zasobach obliczeniowych. W rzeczywistości, aby otrzymać konkluzywne i rzetelne wyniki, należałoby skorzystać co najmniej ze zbioru `CIFAR-10` oraz znacznie większego modelu kodera, np. `ResNet`. Jednak do celów dydaktycznych skorzystamy z mniejszego zbioru oraz odpowiednio mniejszego kodera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600bfc0-49b1-4d1b-911d-5ff61557ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "DATA_DIR = \"./data\"\n",
    "OUT_DIR = \"./data/output/sim_clr\"\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 0\n",
    "NUM_SAMPLES_PER_CLASS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009daf18-03c7-4f79-b0f1-54d376a3aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = VisionDatamodule(\n",
    "    root_dir=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    num_samples_per_class=NUM_SAMPLES_PER_CLASS,\n",
    ")\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202c2ee-eb8c-4763-8262-d24666965a81",
   "metadata": {},
   "source": [
    "# Zadanie 2.1 Implementacja modelu SimCLR (2.0 pkt)\n",
    "W poniższej komórce znajduje się częściowa implementacja modelu `SimCLR`. Uzupełnij brakujące implementacje funkcji:\n",
    "* `forward` (1.0 pkt) - implementuje przejście w przód modelu (augmentacje do dwóch widoków, forward widoków przez `encoder` oraz `projector`), zwraca parę embeddingów.\n",
    "* `info_nce_loss` (1.0 pkt) - funkcja straty modelu `SimCLR`:\n",
    "$$\n",
    "\\ell_{i, j}=-\\log \\frac{\\exp \\left(\\operatorname{sim}\\left(z_i, z_j\\right) / \\tau\\right)}{\\sum_{k=1}^{2 N} \\mathbb{1}_{[k \\neq i]} \\exp \\left(\\operatorname{sim}\\left(z_i, z_k\\right) / \\tau\\right)},\n",
    "$$\n",
    "gdzie $\\operatorname{sim}$ - podobieńśtwo cosinusowe, $\\tau$ - parametr temperatury.\n",
    "\n",
    "Ponadto:\n",
    "* Wykorzystuj metody z torch'a, unikaj pythonowych pętli.\n",
    "* Przeanalizuj dokładnie pozostałe elementy implementacji.\n",
    "* Uruchom uczenie i przeanalizuj wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e1f28-c6a9-4c4c-add7-59301a131f1e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f127c13c858ec8a4f14d59f420e53666",
     "grade": true,
     "grade_id": "simclr-implementation",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class SimCLRModel(SSLBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float,\n",
    "        weight_decay: float,\n",
    "        temp: float,\n",
    "        out_channels: int = 10,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            out_channels=out_channels,\n",
    "        )\n",
    "\n",
    "        # Initialize online network\n",
    "        self.encoder = SmallConvnet()\n",
    "        self.projector = MLP(84, 84, 84, plain_last=True)\n",
    "\n",
    "        self.aug_1 = get_default_aug()\n",
    "        self.aug_2 = get_default_aug()\n",
    "\n",
    "        self.temp = temp\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "        return z_i, z_j\n",
    "\n",
    "    def forward_repr(self, x: Tensor) -> Tensor:\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def training_step(self, batch: Tensor, batch_idx: int) -> Tensor:\n",
    "        x, _ = batch\n",
    "        z_i, z_j = self.forward(x)\n",
    "        loss = self.info_nce_loss(z_i=z_i, z_j=z_j)\n",
    "\n",
    "        self.log(\"train/loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def info_nce_loss(self, z_i: Tensor, z_j: Tensor) -> Tensor:\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95924778-012e-416e-b5c8-65c982f9aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"./data/output/sim_clr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100419f-7cd7-44b9-86f0-a058848d714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "TEMPERATURE = 0.07\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 75\n",
    "ACCELERATOR = \"cpu\" # change to CUDA, if want to train on GPU\n",
    "\n",
    "seed_everything(42)\n",
    "model = SimCLRModel(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    temp=TEMPERATURE,\n",
    ")\n",
    "logger = TensorBoardLogger(save_dir=OUT_DIR, default_hp_metric=False)\n",
    "trainer = Trainer(\n",
    "    default_root_dir=OUT_DIR,\n",
    "    max_epochs=EPOCHS,\n",
    "    logger=logger,\n",
    "    accelerator=ACCELERATOR,\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule)\n",
    "trainer.test(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f066f1bf-b7c8-42a5-ae01-91210e729b68",
   "metadata": {},
   "source": [
    "# Zadanie 2.2 Badanie `batch_size` (1 pkt)\n",
    "Jako jedną z głównych wad metod kontrastowych podaje się wymaganie na stosowanie dużych batch'y. W tym zadaniu:\n",
    "* Sprawdź co najmniej 3 wielkości batch'a\n",
    "* Idelanie będzie wykonać 3-5 powtórzeń dla każdej wartości parametru, ale jeśli ograniczają Cię zasoby wystarczy 1\n",
    "* Z każdym kolejnym uruchominiem uczenia ustawiaj na nowo seed\n",
    "* Wynik na zbiorze testowym wylicz metodą `trainer.test(...)`, a na podstawie wyników sporządź wykres\n",
    "* Co zaobserwowałeś? Wyjaśnij otrzymaną zależność."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e738542-3e4d-42e3-8e36-54705924a54b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4849a035bad3c55acfbbb099925cd25",
     "grade": true,
     "grade_id": "simclr-batch-size",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TU WPISZ KOD\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

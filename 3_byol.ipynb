{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9790f0c",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466003a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Piotr Durniat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a54e5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1cdf68-8b02-44ae-8209-7bf9cf0fef25",
   "metadata": {},
   "source": [
    "# BYOL\n",
    "W niniejszym zeszycie skupimy się na metodzie *Bootsrap Your Own Latent* (BYOL) [(Grill et al., 2020)](https://arxiv.org/abs/2006.07733). **Należy się dokładnie zapoznać z ideą i zasadą działania BYOL** (wykorzystując materiały z wykładu oraz publikacje, bądź inne materiały dostępne w sieci). \n",
    "\n",
    "W niniejszym zeszycie należy wykonać zadania z zakresu implementacji metody BYOL oraz badania jej hiperparametrów. Model oraz trenowanie zaimplementowano z wykorzystaniem `pytorch_lightning`. Żeby zrozumieć dobrze implementacje, należy zapoznać się z klasą bazową `SSLBase` i ewaluacją na zadaniu docelowym, która została w tej klasie zaimplementowana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0035b4d-d7f1-4a68-b519-cb6415f4c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cbe4b31-c797-49d6-9932-ff9a06c98b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "from lightning_fabric import seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning import Trainer\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src.data import VisionDatamodule\n",
    "from src.ssl_base import SSLBase\n",
    "from src.networks import SmallConvnet, MLP\n",
    "from src.augmentations import get_default_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d01b43-f28b-4b7b-98aa-898713849009",
   "metadata": {},
   "source": [
    "# Zbiór danych\n",
    "Do uczenia BYOL wykorzystamy wypróbkowany podzbiór zbioru MNIST. Warto zaznaczyć, że jest to wybór podyktowany tylko i wyłącznie ograniczeniami w zasobach obliczeniowych. W rzeczywistości, aby otrzymać konkluzywne i rzetelne wyniki, należałoby skorzystać co najmniej ze zbioru `CIFAR-10` oraz znacznie większego modelu kodera, np. `ResNet`. Jednak do celów dydaktycznych skorzystamy z mniejszego zbioru oraz odpowiednio mniejszego kodera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1600bfc0-49b1-4d1b-911d-5ff61557ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "DATA_DIR = \"./data\"\n",
    "OUT_DIR = \"./data/output/byol\"\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 0\n",
    "NUM_SAMPLES_PER_CLASS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "009daf18-03c7-4f79-b0f1-54d376a3aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = VisionDatamodule(\n",
    "    root_dir=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    num_samples_per_class=NUM_SAMPLES_PER_CLASS,\n",
    ")\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202c2ee-eb8c-4763-8262-d24666965a81",
   "metadata": {},
   "source": [
    "# Zadanie 3.1 Implementacja modelu BYOL (2.5 pkt)\n",
    "W poniższej komórce znajduje się częściowa implementacja modelu `BYOL`. Uzupełnij brakujące implementacje funkcji:\n",
    "* `copy_and_freeze_module` (0.5 pkt) - kopiuje parametry sieci oraz \"zamraża\" te skopiowane (ustawia brak liczenia gradientu dla skopiowanych parametrów)\n",
    "* `byol_loss` (1.0 pkt) - funkcja straty modelu BYOL (zgodnie z oryginalną publikacją)\n",
    "  $$ \\mathcal{L}_{\\theta, \\zeta} = \\lVert \\bar{q_{\\theta}}(z_{\\theta}) - \\bar{z'_{\\zeta}} \\rVert_2^2 $$\n",
    "  gdzie $\\bar{q_{\\theta}}(z_{\\theta})$ - wektor wyjściowy z predyktora gałęzi `ONLINE`, $\\bar{z'_{\\zeta}}$ - wektor wyjściowy z projektora gałęzi `TARGET`\n",
    "* `update_target_network` (1.0 pkt) - aktualizuje parametry kodera oraz projektora sieci `TARGET`, ustawia je jako średnia krocząca sieci `ONLINE`\n",
    "\n",
    "Ponadto:\n",
    "* Przeanalizuj dokładnie pozostałe elementy implementacji.\n",
    "* Zastanów się, czy wszystkie parametry modelu podlegają uczeniu?\n",
    "* Zastanów dlaczego w funkcji `forward` dodatkowo liczone jest `q_sym` oraz `z_prim_sym`, czy bez tego model będzie nadal działał poprawnie?\n",
    "* Uruchom uczenie i przeanalizuj wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d53e1f28-c6a9-4c4c-add7-59301a131f1e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f2ab7c5116ec665e33daf019a0709fb",
     "grade": true,
     "grade_id": "byol-implementation",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BYOLModel(SSLBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float,\n",
    "        weight_decay: float,\n",
    "        tau: float,\n",
    "        out_channels: int = 10,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            out_channels=out_channels,\n",
    "        )\n",
    "\n",
    "        # Initialize online network\n",
    "        # funkcja f\n",
    "        self.online_encoder = SmallConvnet()\n",
    "\n",
    "        # funkcja g\n",
    "        self.online_projector = MLP(84, 84, 84, plain_last=False)\n",
    "\n",
    "        # funkcja q\n",
    "        self.online_predictor = MLP(84, 84, 84, plain_last=True)\n",
    "        self.online_net = nn.Sequential(\n",
    "            self.online_encoder,\n",
    "            self.online_projector,\n",
    "            self.online_predictor,\n",
    "        )\n",
    "\n",
    "        # Initialize target network with frozen weights\n",
    "        self.target_encoder = self.copy_and_freeze_module(self.online_encoder)\n",
    "        self.target_projector = self.copy_and_freeze_module(self.online_projector)\n",
    "        self.target_net = nn.Sequential(self.target_encoder, self.target_projector)\n",
    "\n",
    "        # Initialize augmentations\n",
    "        self.aug_1 = get_default_aug()\n",
    "        self.aug_2 = get_default_aug()\n",
    "\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        t = self.aug_1(x)\n",
    "        t_prim = self.aug_2(x)\n",
    "\n",
    "        q = self.online_net(t)\n",
    "        q_sym = self.online_net(t_prim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z_prim = self.target_net(t_prim)\n",
    "            z_prim_sym = self.target_net(t)\n",
    "\n",
    "        q = torch.cat([q, q_sym], dim=0)\n",
    "        z_prim = torch.cat([z_prim, z_prim_sym], dim=0)\n",
    "\n",
    "        return q, z_prim\n",
    "\n",
    "    def forward_repr(self, x: Tensor) -> Tensor:\n",
    "        return self.online_encoder(x)\n",
    "\n",
    "    def training_step(self, batch: Tensor, batch_idx: int) -> Tensor:\n",
    "        x, _ = batch\n",
    "        q, z_prim = self.forward(x)\n",
    "        loss = self.byol_loss(q=q, z_prim=z_prim)\n",
    "\n",
    "        self.log(\"train/loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def byol_loss(self, q: Tensor, z_prim: Tensor) -> Tensor:\n",
    "        q = F.normalize(q, dim=-1, p=2)\n",
    "        z_prim = F.normalize(z_prim, dim=-1, p=2)\n",
    "        return (2 - 2 * (q * z_prim).sum(dim=-1)).mean()\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        super().on_train_epoch_end()\n",
    "        self.update_target_network()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_target_network(self) -> None:\n",
    "        for target_param, online_param in zip(\n",
    "            self.target_net.parameters(), self.online_net.parameters()\n",
    "        ):\n",
    "            target_param.data = (\n",
    "                self.tau * target_param.data + (1 - self.tau) * online_param.data\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def copy_and_freeze_module(model: nn.Module) -> nn.Module:\n",
    "        mode_copy = copy.deepcopy(model)\n",
    "        for param in mode_copy.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        return mode_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95924778-012e-416e-b5c8-65c982f9aac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir \"./data/output/byol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5100419f-7cd7-44b9-86f0-a058848d714c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type         | Params\n",
      "--------------------------------------------------\n",
      "0 | online_encoder   | SmallConvnet | 43.6 K\n",
      "1 | online_projector | MLP          | 14.6 K\n",
      "2 | online_predictor | MLP          | 14.4 K\n",
      "3 | online_net       | Sequential   | 72.6 K\n",
      "4 | target_encoder   | SmallConvnet | 43.6 K\n",
      "5 | target_projector | MLP          | 14.6 K\n",
      "6 | target_net       | Sequential   | 58.2 K\n",
      "7 | aug_1            | Sequential   | 0     \n",
      "8 | aug_2            | Sequential   | 0     \n",
      "--------------------------------------------------\n",
      "72.6 K    Trainable params\n",
      "58.2 K    Non-trainable params\n",
      "130 K     Total params\n",
      "0.523     Total estimated model params size (MB)\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74:  70%|███████   | 7/10 [00:01<00:00,  6.88it/s, v_num=4, train/loss=0.0184]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:02<00:00, 14.04it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy         0.7349647283554077\n",
      "         test/f1            0.7248368263244629\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/accuracy': 0.7349647283554077, 'test/f1': 0.7248368263244629}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "TAU = 0.99\n",
    "EPOCHS = 200\n",
    "ACCELERATOR = \"cpu\"  # change to CUDA, if want to train on GPU\n",
    "\n",
    "seed_everything(42)\n",
    "model = BYOLModel(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    tau=TAU,\n",
    ")\n",
    "logger = TensorBoardLogger(save_dir=OUT_DIR, default_hp_metric=False)\n",
    "trainer = Trainer(\n",
    "    default_root_dir=OUT_DIR,\n",
    "    max_epochs=EPOCHS,\n",
    "    logger=logger,\n",
    "    accelerator=ACCELERATOR,\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule)\n",
    "trainer.test(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b47cbac-cbab-4a3e-a5ae-8bf29c2e1e76",
   "metadata": {},
   "source": [
    "# Zadanie 3.2 Znaczenie projektora (0.5 pkt)\n",
    "* Zmodyfikuj klasę modelu BYOL, tak aby nie zawierał on projektora (zarówno w sieci `ONLINE` jak i `TARGET`) i sprawdzić jak różnią się otrzymane wyniki względem poprzedniego eksperymentu\n",
    "* Zinterpretuj otrzymane wyniki, jaka jest rola projektora w tym modelu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61d44b52-43e2-4d22-bfc8-b395692615c0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c322d3652ca77e315c8e5db07c80e2f",
     "grade": true,
     "grade_id": "projector-study",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BYOLWithoutProjectorModel(SSLBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float,\n",
    "        weight_decay: float,\n",
    "        tau: float,\n",
    "        out_channels: int = 10,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            out_channels=out_channels,\n",
    "        )\n",
    "\n",
    "        # Initialize online network\n",
    "        # funkcja f\n",
    "        self.online_encoder = SmallConvnet()\n",
    "\n",
    "        # funkcja q\n",
    "        self.online_predictor = MLP(84, 84, 84, plain_last=True)\n",
    "        self.online_net = nn.Sequential(\n",
    "            self.online_encoder,\n",
    "            self.online_predictor,\n",
    "        )\n",
    "\n",
    "        # Initialize target network with frozen weights\n",
    "        self.target_encoder = self.copy_and_freeze_module(self.online_encoder)\n",
    "        # self.target_projector = self.copy_and_freeze_module(self.online_projector)\n",
    "        self.target_net = nn.Sequential(self.target_encoder)\n",
    "\n",
    "        # Initialize augmentations\n",
    "        self.aug_1 = get_default_aug()\n",
    "        self.aug_2 = get_default_aug()\n",
    "\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        t = self.aug_1(x)\n",
    "        t_prim = self.aug_2(x)\n",
    "\n",
    "        q = self.online_net(t)\n",
    "        q_sym = self.online_net(t_prim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z_prim = self.target_net(t_prim)\n",
    "            z_prim_sym = self.target_net(t)\n",
    "\n",
    "        q = torch.cat([q, q_sym], dim=0)\n",
    "        z_prim = torch.cat([z_prim, z_prim_sym], dim=0)\n",
    "\n",
    "        return q, z_prim\n",
    "\n",
    "    def forward_repr(self, x: Tensor) -> Tensor:\n",
    "        return self.online_encoder(x)\n",
    "\n",
    "    def training_step(self, batch: Tensor, batch_idx: int) -> Tensor:\n",
    "        x, _ = batch\n",
    "        q, z_prim = self.forward(x)\n",
    "        loss = self.byol_loss(q=q, z_prim=z_prim)\n",
    "\n",
    "        self.log(\"train/loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def byol_loss(self, q: Tensor, z_prim: Tensor) -> Tensor:\n",
    "        q = F.normalize(q, dim=-1, p=2)\n",
    "        z_prim = F.normalize(z_prim, dim=-1, p=2)\n",
    "        return (2 - 2 * (q * z_prim).sum(dim=-1)).mean()\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        super().on_train_epoch_end()\n",
    "        self.update_target_network()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_target_network(self) -> None:\n",
    "        for target_param, online_param in zip(\n",
    "            self.target_net.parameters(), self.online_net.parameters()\n",
    "        ):\n",
    "            target_param.data = (\n",
    "                self.tau * target_param.data + (1 - self.tau) * online_param.data\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def copy_and_freeze_module(model: nn.Module) -> nn.Module:\n",
    "        mode_copy = copy.deepcopy(model)\n",
    "        for param in mode_copy.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        return mode_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85510165-29da-413d-9aef-a55498816620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type         | Params\n",
      "--------------------------------------------------\n",
      "0 | online_encoder   | SmallConvnet | 43.6 K\n",
      "1 | online_predictor | MLP          | 14.4 K\n",
      "2 | online_net       | Sequential   | 58.0 K\n",
      "3 | target_encoder   | SmallConvnet | 43.6 K\n",
      "4 | target_net       | Sequential   | 43.6 K\n",
      "5 | aug_1            | Sequential   | 0     \n",
      "6 | aug_2            | Sequential   | 0     \n",
      "--------------------------------------------------\n",
      "58.0 K    Trainable params\n",
      "43.6 K    Non-trainable params\n",
      "101 K     Total params\n",
      "0.406     Total estimated model params size (MB)\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 10/10 [00:02<00:00,  4.45it/s, v_num=6, train/loss=0.940]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:02<00:00, 14.07it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy         0.5804070234298706\n",
      "         test/f1             0.573940098285675\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/accuracy': 0.5804070234298706, 'test/f1': 0.573940098285675}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "TAU = 0.99\n",
    "EPOCHS = 200\n",
    "# ACCELERATOR = \"cpu\"  # change to CUDA, if want to train on GPU\n",
    "ACCELERATOR = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "seed_everything(42)\n",
    "model = BYOLWithoutProjectorModel(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    tau=TAU,\n",
    ")\n",
    "logger = TensorBoardLogger(save_dir=OUT_DIR, default_hp_metric=False)\n",
    "trainer = Trainer(\n",
    "    default_root_dir=OUT_DIR,\n",
    "    max_epochs=EPOCHS,\n",
    "    logger=logger,\n",
    "    accelerator=ACCELERATOR,\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule)\n",
    "trainer.test(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc724a-947c-44c3-8e15-f62d9481d9e8",
   "metadata": {},
   "source": [
    "# Zadanie 3.3 Badanie parametru `tau` w EMA (1 pkt)\n",
    "* Sprawdź jakie wyniki model osiąga dla różnych wartości parametru `tau`, w szczególności przebadaj wartości krańcowe `(0.0, 1.0)`\n",
    "* Idelanie będzie wykonać 3-5 powtórzeń dla każdej wartości parametru, ale jeśli ograniczają Cię zasoby wystarczy 1\n",
    "* Do wyznaczenia metryk wykorzystaj metodę `trainer.test(...)` i przygotuj wykres na podstawie otrzymanych wyników\n",
    "* Pamiętaj, aby badać pierwszą wersję modelu z projektorem, a z każdym kolejnym uruchominiem uczenia ustawiaj na nowo seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff24967-bed7-400f-9942-c1afbcc2862a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8083733d4b4d4fff895f273d503ccf0",
     "grade": true,
     "grade_id": "tau-study",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type         | Params\n",
      "--------------------------------------------------\n",
      "0 | online_encoder   | SmallConvnet | 43.6 K\n",
      "1 | online_projector | MLP          | 14.6 K\n",
      "2 | online_predictor | MLP          | 14.4 K\n",
      "3 | online_net       | Sequential   | 72.6 K\n",
      "4 | target_encoder   | SmallConvnet | 43.6 K\n",
      "5 | target_projector | MLP          | 14.6 K\n",
      "6 | target_net       | Sequential   | 58.2 K\n",
      "7 | aug_1            | Sequential   | 0     \n",
      "8 | aug_2            | Sequential   | 0     \n",
      "--------------------------------------------------\n",
      "72.6 K    Trainable params\n",
      "58.2 K    Non-trainable params\n",
      "130 K     Total params\n",
      "0.523     Total estimated model params size (MB)\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4ce2c4e9eb478aa73278a4093c51d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a189a11f3634048b517dd3201421c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66e564706b34ec99c66bb9ed25a51fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy         0.7242263555526733\n",
      "         test/f1            0.7170793414115906\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name             | Type         | Params\n",
      "--------------------------------------------------\n",
      "0 | online_encoder   | SmallConvnet | 43.6 K\n",
      "1 | online_projector | MLP          | 14.6 K\n",
      "2 | online_predictor | MLP          | 14.4 K\n",
      "3 | online_net       | Sequential   | 72.6 K\n",
      "4 | target_encoder   | SmallConvnet | 43.6 K\n",
      "5 | target_projector | MLP          | 14.6 K\n",
      "6 | target_net       | Sequential   | 58.2 K\n",
      "7 | aug_1            | Sequential   | 0     \n",
      "8 | aug_2            | Sequential   | 0     \n",
      "--------------------------------------------------\n",
      "72.6 K    Trainable params\n",
      "58.2 K    Non-trainable params\n",
      "130 K     Total params\n",
      "0.523     Total estimated model params size (MB)\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec7712d477c458e891e84c828f1faa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad283cda1ce441eb60f680ad0f1929b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c56a5def36d4b79bb5ad5a908ea6aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy         0.7242263555526733\n",
      "         test/f1            0.7170793414115906\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name             | Type         | Params\n",
      "--------------------------------------------------\n",
      "0 | online_encoder   | SmallConvnet | 43.6 K\n",
      "1 | online_projector | MLP          | 14.6 K\n",
      "2 | online_predictor | MLP          | 14.4 K\n",
      "3 | online_net       | Sequential   | 72.6 K\n",
      "4 | target_encoder   | SmallConvnet | 43.6 K\n",
      "5 | target_projector | MLP          | 14.6 K\n",
      "6 | target_net       | Sequential   | 58.2 K\n",
      "7 | aug_1            | Sequential   | 0     \n",
      "8 | aug_2            | Sequential   | 0     \n",
      "--------------------------------------------------\n",
      "72.6 K    Trainable params\n",
      "58.2 K    Non-trainable params\n",
      "130 K     Total params\n",
      "0.523     Total estimated model params size (MB)\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4534fb5c23a4ea7971ed694ac3e3aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b4e5c5bfa844cbb0251397af021b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928ef35e9f994326a019474c751e270d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy         0.7242263555526733\n",
      "         test/f1            0.7170793414115906\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name             | Type         | Params\n",
      "--------------------------------------------------\n",
      "0 | online_encoder   | SmallConvnet | 43.6 K\n",
      "1 | online_projector | MLP          | 14.6 K\n",
      "2 | online_predictor | MLP          | 14.4 K\n",
      "3 | online_net       | Sequential   | 72.6 K\n",
      "4 | target_encoder   | SmallConvnet | 43.6 K\n",
      "5 | target_projector | MLP          | 14.6 K\n",
      "6 | target_net       | Sequential   | 58.2 K\n",
      "7 | aug_1            | Sequential   | 0     \n",
      "8 | aug_2            | Sequential   | 0     \n",
      "--------------------------------------------------\n",
      "72.6 K    Trainable params\n",
      "58.2 K    Non-trainable params\n",
      "130 K     Total params\n",
      "0.523     Total estimated model params size (MB)\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccea566e1b44ec487141791dc15a3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501ae9db94eb47d1b0106236e8cf26fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/home/piotr/projects/ai/ur-l/l03-sr-17-piotrdurniat/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557e17ad04a745448ccf4bd3b2c60afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy         0.7242263555526733\n",
      "         test/f1            0.7170793414115906\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "{0.66: {'test/accuracy': 0.7242263555526733, 'test/f1': 0.7170793414115906}, 0.77: {'test/accuracy': 0.7242263555526733, 'test/f1': 0.7170793414115906}, 0.88: {'test/accuracy': 0.7242263555526733, 'test/f1': 0.7170793414115906}, 0.99: {'test/accuracy': 0.7242263555526733, 'test/f1': 0.7170793414115906}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def test():\n",
    "    # define hyperparameters\n",
    "    LEARNING_RATE = 1e-3\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    EPOCHS = 200\n",
    "    # EPOCHS = 200\n",
    "    # ACCELERATOR = \"cpu\"  # change to CUDA, if want to train on GPU\n",
    "    ACCELERATOR = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    results = {}\n",
    "    taus = [0.66, 0.77, 0.88, 0.99]\n",
    "    for tau in taus:\n",
    "        seed_everything(42)\n",
    "        model = BYOLModel(\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            weight_decay=WEIGHT_DECAY,\n",
    "            tau=tau,\n",
    "        )\n",
    "        logger = TensorBoardLogger(save_dir=OUT_DIR, default_hp_metric=False)\n",
    "        trainer = Trainer(\n",
    "            default_root_dir=OUT_DIR,\n",
    "            max_epochs=EPOCHS,\n",
    "            logger=logger,\n",
    "            accelerator=ACCELERATOR,\n",
    "            num_sanity_val_steps=0,\n",
    "            log_every_n_steps=10,\n",
    "        )\n",
    "\n",
    "        trainer.fit(model, datamodule)\n",
    "        res = trainer.test(model, datamodule)\n",
    "        results[tau] = res[0]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def chart_res(results):\n",
    "    sizes = list(results.keys())\n",
    "    accuracies = [results[size][\"test/accuracy\"] for size in sizes]\n",
    "    f1_scores = [results[size][\"test/f1\"] for size in sizes]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sizes, accuracies, marker=\"o\", linestyle=\"-\", color=\"b\", label=\"Accuracy\")\n",
    "    plt.plot(sizes, f1_scores, marker=\"o\", linestyle=\"-\", color=\"r\", label=\"F1 Score\")\n",
    "\n",
    "    plt.xlabel(\"Size\")\n",
    "    plt.ylabel(\"Scores\")\n",
    "    plt.title(\"Test Accuracy and F1 Score by Size\")\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "results = test()\n",
    "print(results)\n",
    "chart_res(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
